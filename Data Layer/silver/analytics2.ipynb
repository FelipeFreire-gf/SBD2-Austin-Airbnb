{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c81379e",
   "metadata": {},
   "source": [
    " ## conexao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df34c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "# testar se o DDL funcionou\n",
    "DB_CONFIG = {\n",
    "    'host': 'localhost',\n",
    "    'port': '5433',\n",
    "    'database': 'austin_airbnb',\n",
    "    'user': 'postgres',\n",
    "    'password': 'postgres'\n",
    "}\n",
    "\n",
    "try:\n",
    "    conn = psycopg2.connect(**DB_CONFIG)\n",
    "    cur = conn.cursor()\n",
    "    # verifica se a tabela existe\n",
    "    cur.execute(\"SELECT * FROM silver.one_big_table LIMIT 0;\")\n",
    "    print(\"Sucesso! A tabela silver.one_big_table já existe e está pronta para visualização.\")\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "except Exception as e:\n",
    "    print(f\"Erro: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395a857b",
   "metadata": {},
   "source": [
    "pyspark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6af78ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# 1. Configurar a sessão Spark com o driver do Postgres\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"AustinAirbnbValidation\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.postgresql:postgresql:42.6.0\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# 2. Configurações de conexão\n",
    "jdbc_url = \"jdbc:postgresql://localhost:5433/austin_airbnb\"\n",
    "db_properties = {\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"postgres\",\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}\n",
    "\n",
    "# Função auxiliar para ler queries SQL via Spark\n",
    "def read_query(query):\n",
    "    return spark.read.jdbc(url=jdbc_url, table=f\"({query}) as tmp\", properties=db_properties)\n",
    "\n",
    "# 3. Execução das Queries\n",
    "query_listings = \"\"\"\n",
    "SELECT DISTINCT \n",
    "    listing_id, listing_name, property_type, room_type, bed_type,\n",
    "    accommodates, bathrooms, bedrooms, beds,\n",
    "    neighbourhood_cleansed, listing_price as price,\n",
    "    number_of_reviews, first_review, last_review\n",
    "FROM silver.one_big_table\n",
    "\"\"\"\n",
    "df_spark_listings = read_query(query_listings)\n",
    "\n",
    "query_calendar = \"\"\"\n",
    "SELECT DISTINCT\n",
    "    listing_id, calendar_date as date, calendar_available as available\n",
    "FROM silver.one_big_table\n",
    "\"\"\"\n",
    "df_spark_calendar = read_query(query_calendar)\n",
    "\n",
    "query_reviews = \"\"\"\n",
    "SELECT DISTINCT\n",
    "    review_id, listing_id, review_date as date, reviewer_id, reviewer_name\n",
    "FROM silver.one_big_table\n",
    "WHERE review_id IS NOT NULL\n",
    "\"\"\"\n",
    "df_spark_reviews = read_query(query_reviews)\n",
    "\n",
    "# 4. Validação dos Volumes (Contagem distribuída)\n",
    "print(f\"Listings: {df_spark_listings.count():,} registros\")\n",
    "print(f\"Calendar: {df_spark_calendar.count():,} registros\")\n",
    "print(f\"Reviews: {df_spark_reviews.count():,} registros\")\n",
    "\n",
    "# 5. Visualizar amostra \n",
    "df_spark_listings.show(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
